{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 07:34:17 WARN Utils: Your hostname, MBP-SMITH515.local resolves to a loopback address: 127.0.0.1; using 192.168.4.81 instead (on interface en0)\n",
      "23/04/10 07:34:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/10 07:34:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession;\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"ISM6562 Spark App01\").enableHiveSupport().getOrCreate();\n",
    "\n",
    "# Let's get the SparkContext object. It's the entry point to the Spark API. It's created when you create a sparksession\n",
    "sc = spark.sparkContext  \n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)\n",
    "\n",
    "# It's best if you find that the port number displayed below is not 4040, then you should shut down all other spark sessions and \n",
    "# run this code again. If you don't, you may have trouble accessing the data in the spark-warehouse directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will set the log level to ERROR. This will hide the INFO or WARNING messages that are printed out by default. If you want to see them, set this to INFO or WARN.\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.4.81:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ISM6562 Spark App01</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10fb91180>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|   tableName|isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|  default|      boston|      false|\n",
      "|  default|fake_friends|      false|\n",
      "|  default|movieratings|      false|\n",
      "|  default|      movies|      false|\n",
      "|  default|      u_item|      false|\n",
      "+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT movieid)|\n",
      "+-----------------------+\n",
      "|                   1682|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select count(DISTINCT movieid) from movieratings\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  100000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select count(*) from movieratings\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|count|rating|\n",
      "+-----+------+\n",
      "|  583| 4.358|\n",
      "|  509| 3.804|\n",
      "|  508| 4.156|\n",
      "|  507| 4.008|\n",
      "|  485| 3.157|\n",
      "|  481| 3.657|\n",
      "|  478| 3.441|\n",
      "|  452| 3.878|\n",
      "|  431| 3.631|\n",
      "|  429| 3.438|\n",
      "|  420| 4.252|\n",
      "|  413| 4.283|\n",
      "|  394| 4.061|\n",
      "|  392| 3.798|\n",
      "|  390|  4.29|\n",
      "|  384| 3.711|\n",
      "|  378| 3.693|\n",
      "|  367| 4.204|\n",
      "|  365|  3.66|\n",
      "|  350| 4.246|\n",
      "+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRatingCount = spark.sql(\"select count(movieid) as count, round(avg(rating),3) as rating  \\\n",
    "                    from movieratings group by movieid order by count desc, rating desc\")\n",
    "dfRatingCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+\n",
      "|count|rating|features|\n",
      "+-----+------+--------+\n",
      "|  583| 4.358| [583.0]|\n",
      "|  509| 3.804| [509.0]|\n",
      "|  508| 4.156| [508.0]|\n",
      "|  507| 4.008| [507.0]|\n",
      "|  485| 3.157| [485.0]|\n",
      "|  481| 3.657| [481.0]|\n",
      "|  478| 3.441| [478.0]|\n",
      "|  452| 3.878| [452.0]|\n",
      "|  431| 3.631| [431.0]|\n",
      "|  429| 3.438| [429.0]|\n",
      "|  420| 4.252| [420.0]|\n",
      "|  413| 4.283| [413.0]|\n",
      "|  394| 4.061| [394.0]|\n",
      "|  392| 3.798| [392.0]|\n",
      "|  390|  4.29| [390.0]|\n",
      "|  384| 3.711| [384.0]|\n",
      "|  378| 3.693| [378.0]|\n",
      "|  367| 4.204| [367.0]|\n",
      "|  365|  3.66| [365.0]|\n",
      "|  350| 4.246| [350.0]|\n",
      "+-----+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    " \n",
    "# For more on VectorAssembler, see https://spark.apache.org/docs/latest/ml-features.html#vectorassembler \n",
    "dfAssemblerFeature =  VectorAssembler(\n",
    "    inputCols=[\"count\"], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    " \n",
    "dfRatingCount = dfAssemblerFeature.transform(dfRatingCount)\n",
    "dfRatingCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|features|rating|\n",
      "+--------+------+\n",
      "| [583.0]| 4.358|\n",
      "| [509.0]| 3.804|\n",
      "| [508.0]| 4.156|\n",
      "| [507.0]| 4.008|\n",
      "| [485.0]| 3.157|\n",
      "| [481.0]| 3.657|\n",
      "| [478.0]| 3.441|\n",
      "| [452.0]| 3.878|\n",
      "| [431.0]| 3.631|\n",
      "| [429.0]| 3.438|\n",
      "| [420.0]| 4.252|\n",
      "| [413.0]| 4.283|\n",
      "| [394.0]| 4.061|\n",
      "| [392.0]| 3.798|\n",
      "| [390.0]|  4.29|\n",
      "| [384.0]| 3.711|\n",
      "| [378.0]| 3.693|\n",
      "| [367.0]| 4.204|\n",
      "| [365.0]|  3.66|\n",
      "| [350.0]| 4.246|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRatingCount = dfRatingCount.select(\"features\", \"rating\")\n",
    "dfRatingCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [0.0]\n",
      "degreesOfFreedom: [213248]\n",
      "statistics: [339830.8603909695]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.stat import ChiSquareTest\n",
    "r = ChiSquareTest.test(dfRatingCount, \"features\", \"rating\").head()\n",
    " \n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: 0.00418\n",
      "Intercept: 2.82766\n"
     ]
    }
   ],
   "source": [
    "# For more information on LinearRegression, see https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\n",
    "lr = LinearRegression(maxIter=10, featuresCol=\"features\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "# Fit the model\n",
    "lrModel = lr.fit(dfRatingCount)\n",
    " \n",
    " \n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(f\"Coefficients: {lrModel.coefficients[0]:.5f}\")\n",
    "print(f\"Intercept: {lrModel.intercept:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------+\n",
      "|features|rating|        prediction|\n",
      "+--------+------+------------------+\n",
      "| [583.0]| 4.358| 5.263360163655976|\n",
      "| [509.0]| 3.804| 4.954197665501374|\n",
      "| [508.0]| 4.156| 4.950019793904691|\n",
      "| [507.0]| 4.008| 4.945841922308006|\n",
      "| [485.0]| 3.157| 4.853928747180962|\n",
      "| [481.0]| 3.657| 4.837217260794227|\n",
      "| [478.0]| 3.441| 4.824683646004176|\n",
      "| [452.0]| 3.878| 4.716058984490396|\n",
      "| [431.0]| 3.631| 4.628323680960037|\n",
      "| [429.0]| 3.438| 4.619967937766669|\n",
      "| [420.0]| 4.252| 4.582367093396514|\n",
      "| [413.0]| 4.283| 4.553121992219728|\n",
      "| [394.0]| 4.061|4.4737424318827355|\n",
      "| [392.0]| 3.798| 4.465386688689367|\n",
      "| [390.0]|  4.29|    4.457030945496|\n",
      "| [384.0]| 3.711| 4.431963715915897|\n",
      "| [378.0]| 3.693|4.4068964863357944|\n",
      "| [367.0]| 4.204| 4.360939898772272|\n",
      "| [365.0]|  3.66| 4.352584155578905|\n",
      "| [350.0]| 4.246| 4.289916081628647|\n",
      "| [350.0]| 3.834| 4.289916081628647|\n",
      "| [344.0]| 3.314| 4.264848852048544|\n",
      "| [336.0]| 4.045| 4.231425879275074|\n",
      "| [331.0]| 3.931| 4.210536521291655|\n",
      "| [326.0]| 3.632| 4.189647163308235|\n",
      "| [324.0]| 4.173| 4.181291420114868|\n",
      "| [321.0]| 3.854| 4.168757805324817|\n",
      "| [316.0]| 4.066| 4.147868447341398|\n",
      "| [316.0]| 3.123| 4.147868447341398|\n",
      "| [315.0]| 3.927|4.1436905757447136|\n",
      "| [303.0]| 3.746| 4.093556116584508|\n",
      "| [301.0]| 3.934| 4.085200373391141|\n",
      "| [300.0]| 3.833| 4.081022501794457|\n",
      "| [299.0]| 3.896|4.0768446301977725|\n",
      "| [298.0]| 4.466|4.0726667586010885|\n",
      "| [298.0]| 3.698|4.0726667586010885|\n",
      "| [297.0]| 4.162|4.0684888870044045|\n",
      "| [297.0]| 4.152|4.0684888870044045|\n",
      "| [295.0]| 4.007| 4.060133143811037|\n",
      "| [295.0]| 3.424| 4.060133143811037|\n",
      "| [293.0]| 3.778|  4.05177740061767|\n",
      "| [293.0]| 3.444|  4.05177740061767|\n",
      "| [293.0]| 3.215|  4.05177740061767|\n",
      "| [291.0]| 4.034| 4.043421657424302|\n",
      "| [290.0]|  3.91| 4.039243785827618|\n",
      "| [284.0]| 3.947| 4.014176556247516|\n",
      "| [283.0]| 4.445|4.0099986846508315|\n",
      "| [280.0]| 3.775|3.9974650698607803|\n",
      "| [280.0]| 3.764|3.9974650698607803|\n",
      "| [276.0]| 4.163| 3.980753583474045|\n",
      "| [276.0]| 3.931| 3.980753583474045|\n",
      "| [275.0]| 4.138| 3.976575711877361|\n",
      "| [272.0]| 3.485|  3.96404209708731|\n",
      "| [268.0]| 4.011|3.9473306107005746|\n",
      "| [267.0]| 4.386|3.9431527391038905|\n",
      "| [267.0]| 3.644|3.9431527391038905|\n",
      "| [264.0]| 4.292|3.9306191243138393|\n",
      "| [261.0]|  3.72|3.9180855095237876|\n",
      "| [259.0]| 3.969|  3.90972976633042|\n",
      "| [259.0]| 2.981|  3.90972976633042|\n",
      "| [256.0]| 3.875| 3.897196151540369|\n",
      "| [256.0]| 3.793| 3.897196151540369|\n",
      "| [255.0]| 3.792|3.8930182799436848|\n",
      "| [254.0]| 3.031|3.8888404083470007|\n",
      "| [251.0]| 3.916|3.8763067935569495|\n",
      "| [251.0]| 3.837|3.8763067935569495|\n",
      "| [251.0]| 3.661|3.8763067935569495|\n",
      "| [251.0]| 3.594|3.8763067935569495|\n",
      "| [250.0]| 3.884|3.8721289219602655|\n",
      "| [247.0]| 3.785|3.8595953071702143|\n",
      "| [246.0]| 4.077|3.8554174355735302|\n",
      "| [244.0]| 3.816| 3.847061692380163|\n",
      "| [244.0]| 3.557| 3.847061692380163|\n",
      "| [243.0]| 4.457| 3.842883820783479|\n",
      "| [243.0]| 3.872| 3.842883820783479|\n",
      "| [241.0]| 4.058|3.8345280775901114|\n",
      "| [240.0]| 3.108| 3.830350205993428|\n",
      "| [240.0]| 2.933| 3.830350205993428|\n",
      "| [239.0]| 4.105|3.8261723343967438|\n",
      "| [239.0]|   4.1|3.8261723343967438|\n",
      "| [236.0]| 3.847|3.8136387196066925|\n",
      "| [232.0]| 3.685| 3.796927233219957|\n",
      "| [231.0]| 4.121|3.7927493616232733|\n",
      "| [230.0]| 3.648| 3.788571490026589|\n",
      "| [230.0]| 3.304| 3.788571490026589|\n",
      "| [227.0]| 3.881| 3.776037875236538|\n",
      "| [227.0]| 3.863| 3.776037875236538|\n",
      "| [226.0]| 3.951| 3.771860003639854|\n",
      "| [223.0]|  3.57|3.7593263888498027|\n",
      "| [222.0]| 3.766|3.7551485172531187|\n",
      "| [221.0]| 4.045| 3.750970645656435|\n",
      "| [221.0]|  3.91| 3.750970645656435|\n",
      "| [221.0]| 3.611| 3.750970645656435|\n",
      "| [220.0]| 3.782| 3.746792774059751|\n",
      "| [220.0]| 3.482| 3.746792774059751|\n",
      "| [219.0]| 4.292|3.7426149024630675|\n",
      "| [219.0]| 3.995|3.7426149024630675|\n",
      "| [219.0]| 3.813|3.7426149024630675|\n",
      "| [219.0]| 2.808|3.7426149024630675|\n",
      "| [218.0]| 3.087|3.7384370308663835|\n",
      "+--------+------+------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRatingCount = lrModel.transform(dfRatingCount)\n",
    "dfRatingCount.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7056\n",
      "r2: 0.1846\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(f\"RMSE: {trainingSummary.rootMeanSquaredError:.4f}\")\n",
    "print(f\"r2: {trainingSummary.r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
